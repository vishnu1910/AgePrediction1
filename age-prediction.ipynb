{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":74586,"databundleVersionId":8130765,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Step 1: Data Preparation\ntrain_df = pd.read_csv('/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv')\n\n# Split data into training, validation, and testing sets\ntrain_data, test_data = train_test_split(train_df, test_size=0.2, random_state=42)\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n\n# Data preprocessing functions (e.g., resize, normalize)\n\nimg_height = 224\nimg_width = 224\nbatch_size = 32\nepochs =5 \n# Step 2: Model Building\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)  # Output layer for regression\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Step 3: Model Training\n# Data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_data,\n    directory='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train/',\n    x_col='file_id',\n    y_col='age',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='raw')\n\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_data,\n    directory='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train/',\n    x_col='file_id',\n    y_col='age',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='raw')\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_data,\n    directory='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train/',\n    x_col='file_id',\n    y_col='age',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='raw',\n    shuffle=False)\n\nhistory = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n\n# Step 4: Model Evaluation\nloss = model.evaluate(test_generator)\nprint(\"Test Loss:\", loss)\n\n# Step 5: Deployment\n# Save the model for future use\nmodel.save('age_prediction_model.h5')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T20:48:35.547340Z","iopub.execute_input":"2024-04-08T20:48:35.548087Z","iopub.status.idle":"2024-04-08T21:05:53.401072Z","shell.execute_reply.started":"2024-04-08T20:48:35.548052Z","shell.execute_reply":"2024-04-08T21:05:53.400070Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Found 13657 validated image filenames.\nFound 3415 validated image filenames.\nFound 4268 validated image filenames.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/427\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:24\u001b[0m 15s/step - loss: 1257.7145","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1712609342.890915      89 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1712609342.908709      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529ms/step - loss: 389.2455","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1712609569.206529      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 571ms/step - loss: 389.1262 - val_loss: 272.7801\nEpoch 2/5\n\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 431ms/step - loss: 297.4511 - val_loss: 247.9888\nEpoch 3/5\n\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 431ms/step - loss: 285.9945 - val_loss: 254.6792\nEpoch 4/5\n\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 429ms/step - loss: 264.4639 - val_loss: 251.9907\nEpoch 5/5\n\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 431ms/step - loss: 256.0478 - val_loss: 209.2642\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 145ms/step - loss: 202.5833\nTest Loss: 202.43115234375\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Define your CNN model\nclass AgePredictionModel(nn.Module):\n    def __init__(self):\n        super(AgePredictionModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(128 * 28 * 28, 64)\n        self.fc2 = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = self.pool(torch.relu(self.conv3(x)))\n        x = torch.flatten(x, 1)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Define a custom dataset class\nclass AgeDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx, 0]\n        image = Image.open(self.root_dir + img_name)\n        age = self.data.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        return image, age\n\n# Load data and split into train, val, and test sets\ndata = pd.read_csv('/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv')\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Create datasets and dataloaders\ntrain_dataset = AgeDataset(csv_file='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv', root_dir='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train/', transform=transform)\nval_dataset = AgeDataset(csv_file='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv', root_dir='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train/', transform=transform)\ntest_dataset = AgeDataset(csv_file='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train.csv', root_dir='/kaggle/input/smai-24-age-prediction/content/faces_dataset/train/', transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialize model, loss function, and optimizer\nmodel = AgePredictionModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nepochs = 10\n# Train the model\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs.squeeze(), labels.float())\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    epoch_loss = running_loss / len(train_loader.dataset)\n    \n    # Validate the model\n    model.eval()\n    val_loss = 0.0\n    val_mae = 0.0\n    val_rmse = 0.0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs.squeeze(), labels.float())\n            val_loss += loss.item() * inputs.size(0)\n            val_mae += mean_absolute_error(labels.cpu().numpy(), outputs.cpu().numpy())\n            val_rmse += mean_squared_error(labels.cpu().numpy(), outputs.cpu().numpy(), squared=False)\n    val_loss /= len(val_loader.dataset)\n    val_mae /= len(val_loader.dataset)\n    val_rmse /= len(val_loader.dataset)\n    \n    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}, Val RMSE: {val_rmse:.4f}')\n\n# Test the model\nmodel.eval()\ntest_loss = 0.0\ntest_mae = 0.0\ntest_rmse = 0.0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs.squeeze(), labels.float())\n        test_loss += loss.item() * inputs.size(0)\n        test_mae += mean_absolute_error(labels.cpu().numpy(), outputs.cpu().numpy())\n        test_rmse += mean_squared_error(labels.cpu().numpy(), outputs.cpu().numpy(), squared=False)\ntest_loss /= len(test_loader.dataset)\ntest_mae /= len(test_loader.dataset)\ntest_rmse /= len(test_loader.dataset)\nprint(f'Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}, Test RMSE: {test_rmse:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:36:02.752334Z","iopub.execute_input":"2024-04-09T22:36:02.752965Z","iopub.status.idle":"2024-04-09T23:02:38.753428Z","shell.execute_reply.started":"2024-04-09T22:36:02.752933Z","shell.execute_reply":"2024-04-09T23:02:38.752383Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch [1/10], Train Loss: 249.3024, Val Loss: 196.0022, Val MAE: 0.3191, Val RMSE: 0.3790\nEpoch [2/10], Train Loss: 151.0959, Val Loss: 117.2479, Val MAE: 0.2460, Val RMSE: 0.3015\nEpoch [3/10], Train Loss: 114.9866, Val Loss: 93.1071, Val MAE: 0.2307, Val RMSE: 0.2855\nEpoch [4/10], Train Loss: 93.9735, Val Loss: 79.2654, Val MAE: 0.2122, Val RMSE: 0.2674\nEpoch [5/10], Train Loss: 77.5517, Val Loss: 73.1018, Val MAE: 0.2024, Val RMSE: 0.2558\nEpoch [6/10], Train Loss: 67.5468, Val Loss: 54.7141, Val MAE: 0.1713, Val RMSE: 0.2140\nEpoch [7/10], Train Loss: 60.1001, Val Loss: 58.6312, Val MAE: 0.1857, Val RMSE: 0.2343\nEpoch [8/10], Train Loss: 50.8804, Val Loss: 39.8895, Val MAE: 0.1494, Val RMSE: 0.1898\nEpoch [9/10], Train Loss: 42.3905, Val Loss: 32.7313, Val MAE: 0.1359, Val RMSE: 0.1712\nEpoch [10/10], Train Loss: 35.8799, Val Loss: 29.4340, Val MAE: 0.1303, Val RMSE: 0.1658\nTest Loss: 29.4340, Test MAE: 0.1303, Test RMSE: 0.1658\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'age_prediction_model_pytorch.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T23:12:47.437545Z","iopub.execute_input":"2024-04-09T23:12:47.438224Z","iopub.status.idle":"2024-04-09T23:12:47.486563Z","shell.execute_reply.started":"2024-04-09T23:12:47.438194Z","shell.execute_reply":"2024-04-09T23:12:47.485378Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'age_prediction_model_pytorch.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T23:13:48.941373Z","iopub.execute_input":"2024-04-09T23:13:48.942303Z","iopub.status.idle":"2024-04-09T23:13:48.982621Z","shell.execute_reply.started":"2024-04-09T23:13:48.942268Z","shell.execute_reply":"2024-04-09T23:13:48.981801Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom PIL import Image\n\n# Define transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Load the image\nimage_path = '/kaggle/input/smai-24-age-prediction/content/faces_dataset/test/image_1002.jpg'  # Change this to the path of your sample image\nimage = Image.open(image_path)\n\n# Preprocess the image\ninput_image = transform(image).unsqueeze(0)  # Add batch dimension\n\n# Load the model\nmodel = AgePredictionModel().to(device)\nmodel.load_state_dict(torch.load('/kaggle/working/age_prediction_model_pytorch.pth'))  # Load the trained model\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Move input image to GPU if available\ninput_image = input_image.to(device)\n\n# Get the prediction\nwith torch.no_grad():\n    output = model(input_image)\n\npredicted_age = output.item()\nprint(\"Predicted Age:\", predicted_age)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T23:18:42.723021Z","iopub.execute_input":"2024-04-09T23:18:42.723381Z","iopub.status.idle":"2024-04-09T23:18:42.812349Z","shell.execute_reply.started":"2024-04-09T23:18:42.723354Z","shell.execute_reply":"2024-04-09T23:18:42.811381Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Predicted Age: 74.74285125732422\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}